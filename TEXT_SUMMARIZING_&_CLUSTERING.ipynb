{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a34c4fe8-1f0d-4ef4-9f80-2b7030b73ab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\RANGUMUDRI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RANGUMUDRI\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      " \n",
      "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The ultimate objective of NLP is to enable computers to understand, interpret, and generate human languages in a valuable way. In practice, this involves various tasks such as text classification, machine translation, speech recognition, and sentiment analysis, among others.\n",
      "The complexity of human language makes NLP a particularly challenging field in AI, as it requires a deep understanding of both linguistic theory and computational techniques. Modern NLP often relies on machine learning algorithms, especially deep learning models, to automatically learn the intricacies of language from large datasets.\n",
      "\n",
      "\n",
      "Summary:\n",
      " Modern NLP often relies on machine learning algorithms, especially deep learning models, to automatically learn the intricacies of language from large datasets. \n",
      "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Download necessary NLTK data\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "# Sample text\n",
    "text = \"\"\"\n",
    "Natural language processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and humans through natural language. The ultimate objective of NLP is to enable computers to understand, interpret, and generate human languages in a valuable way. In practice, this involves various tasks such as text classification, machine translation, speech recognition, and sentiment analysis, among others.\n",
    "The complexity of human language makes NLP a particularly challenging field in AI, as it requires a deep understanding of both linguistic theory and computational techniques. Modern NLP often relies on machine learning algorithms, especially deep learning models, to automatically learn the intricacies of language from large datasets.\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text into sentences\n",
    "    sentences = sent_tokenize(text)\n",
    "    \n",
    "    # Tokenize the sentences into words\n",
    "    words = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
    "    #(list of words from sentence) \n",
    "    \n",
    "    # Remove stopwords and non-alphanumeric words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_words = [[word for word in word_list if word.isalnum() and word not in stop_words] for word_list in words]\n",
    "    \n",
    "    # word.isalnum() checks if the word is alphanumeric (contains only letters and numbers). \n",
    "    # This helps filter out punctuation, special characters, etc. For example, it would remove '(' and ')' from the example above.\n",
    "    \n",
    "    return sentences, filtered_words\n",
    "\n",
    "# Rank sentences based on word frequency\n",
    "def rank_sentences(sentences, filtered_words):\n",
    "    # Flatten the list of filtered words\n",
    "    flat_words = [word for sublist in filtered_words for word in sublist]\n",
    "    # Flattening the List: The code flattens filtered_words into a single list called flat_words. \n",
    "    # Instead of having a list of lists, you'll end up with a single list containing all the words.\n",
    "    \n",
    "    # Calculate word frequency distribution\n",
    "    word_freq = FreqDist(flat_words)\n",
    "\n",
    "    # Score each sentence by summing the frequency of the words in it\n",
    "    sentence_scores = defaultdict(int)\n",
    "    for i, word_list in enumerate(filtered_words):\n",
    "        # sentence_scores[i] += word_freq[word]: This adds the frequency of the current word to the score of the sentence at index i in the sentence_scores dictionary.\n",
    "        for word in word_list:\n",
    "            sentence_scores[i] += word_freq[word]\n",
    "    \n",
    "    # Sort sentences by score\n",
    "    ranked_sentences = sorted(sentence_scores.items(), key=lambda item: item[1], reverse=True)\n",
    "    # key=lambda item: item[1] above fun gives tuples as o/p,in that item[1] means selecting rank wise means key,value anuko, based on value ani\n",
    "    return ranked_sentences\n",
    "\n",
    "# Generate summary\n",
    "def summarize(text, n=2):\n",
    "    # Preprocess the text\n",
    "    sentences, filtered_words = preprocess_text(text)\n",
    "    \n",
    "    # Rank sentences\n",
    "    ranked_sentences = rank_sentences(sentences, filtered_words)\n",
    "    \n",
    "    # Extract the top n sentences for the summary\n",
    "    summary_sentences = [sentences[idx] for idx, score in ranked_sentences[:n]]\n",
    "    #  means top index lu evaite vasthayo aa indexes tho unna sentences ni idi summary_sentences lo peduthundi\n",
    "    # Combine the summary sentences into a single string\n",
    "    summary = ' '.join(summary_sentences)\n",
    "    \n",
    "    return summary\n",
    "\n",
    "# Summarize the text\n",
    "summary = summarize(text, n=2)\n",
    "print(\"Original Text:\\n\", text)\n",
    "print(\"\\nSummary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "954c385a-9297-4e56-a508-d3c1213df6d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\RANGUMUDRI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1:\n",
      " - Text clustering is an unsupervised learning technique.\n",
      " - K-means is a popular clustering algorithm.\n",
      " - Unsupervised learning works with unlabeled data.\n",
      "Cluster 2:\n",
      " - Natural language processing is a branch of artificial intelligence.\n",
      " - Artificial intelligence is the future of technology.\n",
      "Cluster 3:\n",
      " - Machine learning enables computers to learn from data.\n",
      " - Deep learning is a subset of machine learning.\n",
      " - Supervised learning requires labeled data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Sample text data\n",
    "documents = [\n",
    "    \"Natural language processing is a branch of artificial intelligence.\", \n",
    "    \"Machine learning enables computers to learn from data.\",\n",
    "    \"Deep learning is a subset of machine learning.\",\n",
    "    \"Artificial intelligence is the future of technology.\",\n",
    "    \"Text clustering is an unsupervised learning technique.\",\n",
    "    \"K-means is a popular clustering algorithm.\",\n",
    "    \"Supervised learning requires labeled data.\",\n",
    "    \"Unsupervised learning works with unlabeled data.\"\n",
    "]\n",
    "\n",
    "# Preprocess the text\n",
    "def preprocess_text(documents):\n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    processed_docs = []\n",
    "    \n",
    "    for doc in documents:\n",
    "        words = nltk.word_tokenize(doc.lower())\n",
    "        filtered_words = [word for word in words if word.isalnum() and word not in stop_words]\n",
    "        processed_docs.append(\" \".join(filtered_words))\n",
    "        # where the goal is often to group similar documents together based on meaning,\n",
    "        # preserving the original word form can be more beneficial.\n",
    "    \n",
    "    return processed_docs\n",
    "\n",
    "# Preprocess the documents\n",
    "processed_docs = preprocess_text(documents) # processed_docs name was not in outside...it was only in def, so initialize it\n",
    "\n",
    "# Convert documents to TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(processed_docs)\n",
    "\n",
    "# Apply K-Means clustering\n",
    "num_clusters = 3  # You can change the number of clusters\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=0)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Print the clusters and their respective documents\n",
    "clusters = kmeans.labels_.tolist()\n",
    "for i in range(num_clusters): # 0,1,2 are the range\n",
    "    print(f\"Cluster {i+1}:\")  # i = 0 +1 = 1,   i = 1 +1 = 2,  i = 2 +1 = 3....for cluster numbering from 1 to so on\n",
    "    for idx, label in enumerate(clusters): # [1, 2, 2, 1, 0, 0, 2, 0]\n",
    "        if label == i:\n",
    "            print(f\" - {documents[idx]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f5394d-e56e-4fb0-b8a4-d5fcf4320717",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
